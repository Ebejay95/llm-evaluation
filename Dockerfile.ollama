# Dockerfile.ollama
FROM ubuntu:22.04

ENV DEBIAN_FRONTEND=noninteractive

# ---- Basis ----
RUN apt-get update && apt-get install -y \
    curl ca-certificates jq \
 && rm -rf /var/lib/apt/lists/*

# Ollama installieren
RUN curl -fsSL https://ollama.ai/install.sh | sh

# Models-Verzeichnis (optional)
ENV OLLAMA_MODELS=/root/.ollama
# Auf allen Interfaces lauschen
ENV OLLAMA_HOST=0.0.0.0

# Vorab ein paar kleine Modelle ziehen (Server kurz im Hintergrund starten)
RUN ollama serve & \
    sleep 10 && \
    ollama pull llama3.2:1b && \
    ollama pull qwen2:0.5b && \
    pkill ollama

EXPOSE 11434

# Healthcheck f√ºr compose
HEALTHCHECK --interval=5s --timeout=3s --retries=20 \
  CMD curl -fsS http://localhost:11434/api/version || exit 1

# Final: Server starten
CMD ["ollama","serve"]
